{"title":"PyTorch Note (1) —— Tensors and Operations","date":"2018-06-15T07:00:00.000Z","date_formatted":{"ll":"Jun 15, 2018","L":"06/15/2018","MM-DD":"06-15"},"link":"post/pytorch_tensor_operation","tags":["Frameworks","PyTorch"],"categories":["学习笔记"],"updated":"2019-05-04T03:50:20.000Z","content":"<p>最近听说 PyTorch 很好用，所以就开始看一下。起码不用每次想看 tensor 维度的时候都必须要 feed 然后 run session。PyTorch 中的张量实现非常类似于 Numpy 中的 <code>ndarray</code>，因此在使用时有很多地方很类似于 Numpy。这里就记录一些 PyTorch 的常用接口。</p>\n<a id=\"more\"></a><h1 id=\"张量生成\">张量生成<a href=\"#张量生成\" title=\"张量生成\"></a></h1><p>张量 (tensor)，是运算的基本单位，几乎所有的操作都是基于 tensor 来进行的。对于一个 tensor，我们需要以下几个要素来确定它</p>\n<blockquote>\n<ul><li>维度</li>\n<li>数据类型</li>\n<li>初始值</li>\n</ul></blockquote>\n<p>维度和数据类型自不必说，通常都作为参数传入接口来生成一定大小的 tensor。而对于初始值，我们可以选取零初始、随机数或者一个指定的概率分布。类似于 Numpy，PyTorch 提供了很多生成 tensor 的接口。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按照维度生成空的/随机的tensor</span></span><br><span class=\"line\">x = torch.empty(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">y = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 指定数据类型</span></span><br><span class=\"line\">z = torch.zeros(<span class=\"number\">5</span>, <span class=\"number\">3</span>, dtype=torch.long)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 直接由数据生成tensor，类似于np.array()的用法</span></span><br><span class=\"line\">k = torch.tensor([<span class=\"number\">5.5</span>, <span class=\"number\">3</span>])</span><br></pre></td></tr></table></figure><p>除了上述的的生成方法，PyTorch 还支持通过已有的 tensor 来生成新的 tensor。已有的 tensor 可以作为一个对象，调用一些方法来改变值，也可以作为参数传入一个方法中来返回一个想要的 tensor。在没有指定的情况下，PyTorch 会保留原有张量的性质。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 直接改变已有tensor的维度、数值以及类型</span></span><br><span class=\"line\"><span class=\"comment\"># 得到一个 5*3 的全1张量</span></span><br><span class=\"line\">k = k.new_ones(<span class=\"number\">5</span>, <span class=\"number\">3</span>, dtype=torch.double)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 改变数值，全1变成随机，并改变数据类型</span></span><br><span class=\"line\"><span class=\"comment\"># 但是不改变维度</span></span><br><span class=\"line\">k = torch.randn_like</span><br></pre></td></tr></table></figure><p>另外，在 debug 的时候，Numpy 为我们提供了 <code>ndarray.shape</code> 这样的 attribute 来方便的查看矩阵的维度。而 PyTorch 中的 tensor 就相当于 Numpy 中的 ndarray，也有这样的接口来方便的查看 tensor 的维度 —— <code>k.size()</code>。这个方法会返回一个 <code>torch.Size</code> 对象，实际上是一个 tuple。 </p>\n<h1 id=\"张量运算\">张量运算<a href=\"#张量运算\" title=\"张量运算\"></a></h1><p>对于 tensor 的运算操作，有非常多的形式。以相加为例，就有一下几种形式</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">y = torch.rand(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用运算符</span></span><br><span class=\"line\">print(x+y)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 使用PyTorch内建函数</span></span><br><span class=\"line\">print(torch.add(x, y))</span><br></pre></td></tr></table></figure><p>以上的两种方法均是产生一个右值，我们可以将结果直接赋值给一个变量。而下面的两种方法，将使得计算结果改写一个已有的tensor</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 使用作为输出的tensor当做参数</span></span><br><span class=\"line\">result = torch.empty(<span class=\"number\">5</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">torch.add(x, y, out=result)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 像一个tensor的值加到另一个上面</span></span><br><span class=\"line\"><span class=\"comment\"># 改写参与运算的其中一个tensor</span></span><br><span class=\"line\">y.add_(x)</span><br></pre></td></tr></table></figure><p>需要改变的tensor作为一个对象，调用对应的运算方法来改变自身的值：<code>y &lt;- y + x</code>。任何替换 tensor 自身数值的操作都是以 <code>_</code> 所谓后缀的。</p>\n<h1 id=\"选取张量中的指定元素\">选取张量中的指定元素<a href=\"#选取张量中的指定元素\" title=\"选取张量中的指定元素\"></a></h1><p>PyTorch 支持所有标准Numpy 下标索引语法。一般的索引都是用 <code>slice</code> 对象实现，格式为 <code>start:stop:step</code>。基于这种格式，下面是几个例子</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x = np.array([<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x[<span class=\"number\">3</span>:]</span><br><span class=\"line\">array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x[<span class=\"number\">3</span>::]</span><br><span class=\"line\">array([<span class=\"number\">4</span>, <span class=\"number\">5</span>, <span class=\"number\">6</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&gt;&gt;&gt; </span>x[::<span class=\"number\">2</span>]</span><br><span class=\"line\">array([<span class=\"number\">1</span>, <span class=\"number\">3</span>, <span class=\"number\">5</span>])</span><br></pre></td></tr></table></figure><p>可以看到，<code>:</code> 或者<code>::</code> 单独出现在一个数字后面的时候，就表示将这一维度上的所有选出。可以视作对终止位置和步长的省略（默认为最后一个元素和1步长）。值得注意的是最后一个操作，省略的起始和终止，只对步长做了说明，这样就会在原矩阵中的某一维度上等距的选取元素。</p>\n<h1 id=\"张量的-resize\">张量的 resize<a href=\"#张量的-resize\" title=\"张量的 resize\"></a></h1><p>如果想要 resize 一个 tensor，就需要 <code>torch.view</code>。就是这个张量的名字，起的实在是不怎么直观。参数是各个维度的数值，而设定为 -1 的维度则会由其他维度的大小以及总元素的个数推断出来。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x = torch.randn(<span class=\"number\">4</span>, <span class=\"number\">4</span>)</span><br><span class=\"line\">y = x.view(<span class=\"number\">16</span>)</span><br><span class=\"line\">z = x.view(<span class=\"number\">-1</span>, <span class=\"number\">8</span>)  <span class=\"comment\"># the size -1 is inferred from other dimensions</span></span><br><span class=\"line\">print(x)</span><br><span class=\"line\">print(z)</span><br><span class=\"line\">print(x.size(), y.size(), z.size())</span><br><span class=\"line\"></span><br><span class=\"line\">tensor([[<span class=\"number\">-1.1173</span>, <span class=\"number\">-1.2871</span>, <span class=\"number\">-0.0458</span>, <span class=\"number\">-0.2737</span>],</span><br><span class=\"line\">        [<span class=\"number\">-0.4851</span>,  <span class=\"number\">1.3128</span>, <span class=\"number\">-0.6147</span>,  <span class=\"number\">0.2434</span>],</span><br><span class=\"line\">        [ <span class=\"number\">0.6655</span>,  <span class=\"number\">1.2270</span>,  <span class=\"number\">1.1213</span>, <span class=\"number\">-0.1862</span>],</span><br><span class=\"line\">        [<span class=\"number\">-0.6330</span>,  <span class=\"number\">0.0598</span>,  <span class=\"number\">0.3160</span>,  <span class=\"number\">0.4627</span>]])</span><br><span class=\"line\">tensor([[<span class=\"number\">-1.1173</span>, <span class=\"number\">-1.2871</span>, <span class=\"number\">-0.0458</span>, <span class=\"number\">-0.2737</span>, <span class=\"number\">-0.4851</span>,  <span class=\"number\">1.3128</span>, <span class=\"number\">-0.6147</span>,</span><br><span class=\"line\">          <span class=\"number\">0.2434</span>],</span><br><span class=\"line\">        [ <span class=\"number\">0.6655</span>,  <span class=\"number\">1.2270</span>,  <span class=\"number\">1.1213</span>, <span class=\"number\">-0.1862</span>, <span class=\"number\">-0.6330</span>,  <span class=\"number\">0.0598</span>,  <span class=\"number\">0.3160</span>,</span><br><span class=\"line\">          <span class=\"number\">0.4627</span>]])</span><br><span class=\"line\">torch.Size([<span class=\"number\">4</span>, <span class=\"number\">4</span>]) torch.Size([<span class=\"number\">16</span>]) torch.Size([<span class=\"number\">2</span>, <span class=\"number\">8</span>])</span><br></pre></td></tr></table></figure><h1 id=\"torch-tensor-和-numpy-array-的转换\">Torch tensor 和 Numpy array 的转换<a href=\"#torch-tensor-和-numpy-array-的转换\" title=\"Torch tensor 和 Numpy array 的转换\"></a></h1><p>这二者之间的转换在这一框架下是很容易的，它们会共享底层的内存，一旦其中一个改变，另一个就会跟着改变。不管谁作为原始数据，改变都会同时发生</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">a = torch.ones(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Convert pytorch tnesor to numpy array</span></span><br><span class=\"line\">b = a.numpy()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ========================== #</span></span><br><span class=\"line\"></span><br><span class=\"line\">a = np.ones(<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Convert numpy array to pytorch tensor</span></span><br><span class=\"line\">b = torch.from_numpy(a)</span><br></pre></td></tr></table></figure><h1 id=\"cuda-tensors\">CUDA Tensors<a href=\"#cuda-tensors\" title=\"CUDA Tensors\"></a></h1><p>PyTorch 支持将 tensor 移动到任意的硬件上进行计算，使用方法 <code>.to</code> 即可实现。不过在这之前我们需要检查 CUDA 是否可用。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># let us run this cell only if CUDA is available</span></span><br><span class=\"line\"><span class=\"comment\"># We will use ``torch.device`` objects to move tensors in and out of GPU</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> torch.cuda.is_available():</span><br><span class=\"line\">    device = torch.device(<span class=\"string\">\"cuda\"</span>)          <span class=\"comment\"># a CUDA device object</span></span><br><span class=\"line\">    y = torch.ones_like(x, device=device)  <span class=\"comment\"># directly create a tensor on GPU</span></span><br><span class=\"line\">    x = x.to(device)                       <span class=\"comment\"># or just use strings ``.to(\"cuda\")``</span></span><br><span class=\"line\">    z = x + y</span><br><span class=\"line\">    print(z)</span><br><span class=\"line\">    print(z.to(<span class=\"string\">\"cpu\"</span>, torch.double))       <span class=\"comment\"># ``.to`` can also change dtype together!</span></span><br></pre></td></tr></table></figure><h1 id=\"reference\">Reference<a href=\"#reference\" title=\"Reference\"></a></h1><ul><li><a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#\" target=\"_blank\">PyTorch tutorial: What is PyTorch</a></li>\n<li><a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html\" target=\"_blank\">Numpy indexing</a></li>\n</ul>","prev":{"title":"经典的降维方法——PCA","link":"post/PCA"},"next":{"title":"Morphological Operation","link":"post/morphologic_operation"},"plink":"https://magi003769.github.io/post/pytorch_tensor_operation/","toc":[{"id":"张量生成","title":"张量生成","index":"1"},{"id":"张量运算","title":"张量运算","index":"2"},{"id":"选取张量中的指定元素","title":"选取张量中的指定元素","index":"3"},{"id":"张量的-resize","title":"张量的 resize","index":"4"},{"id":"torch-tensor-和-numpy-array-的转换","title":"Torch tensor 和 Numpy array 的转换","index":"5"},{"id":"cuda-tensors","title":"CUDA Tensors","index":"6"},{"id":"reference","title":"Reference","index":"7"}]}