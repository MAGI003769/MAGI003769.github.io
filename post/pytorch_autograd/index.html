<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-doge.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-doge.jpg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css">
  <script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js"></script>

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"magi003769.github.io","root":"/","scheme":"Gemini","version":"8.0.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"sidebar":"fadeIn"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content="autograd 包是 pytorch 构建神经网络的核心。他为所有的张量运算提供了自动求导的方法。而这是一个 define-by-run 的框架，这意味着反向传播的过程取决于你的代码如何运行。甚至每一次迭代都可以有所不同。">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch Note (2) —— Autograd">
<meta property="og:url" content="https://magi003769.github.io/post/pytorch_autograd/index.html">
<meta property="og:site_name" content="QueinDecim">
<meta property="og:description" content="autograd 包是 pytorch 构建神经网络的核心。他为所有的张量运算提供了自动求导的方法。而这是一个 define-by-run 的框架，这意味着反向传播的过程取决于你的代码如何运行。甚至每一次迭代都可以有所不同。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://post-pic.nos-eastchina1.126.net/PyTorch/leaf.PNG">
<meta property="article:published_time" content="2018-06-21T16:00:00.000Z">
<meta property="article:modified_time" content="2020-05-10T23:09:36.000Z">
<meta property="article:author" content="Jeff Wong">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="Frameworks">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://post-pic.nos-eastchina1.126.net/PyTorch/leaf.PNG">


<link rel="canonical" href="https://magi003769.github.io/post/pytorch_autograd/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>PyTorch Note (2) —— Autograd | QueinDecim</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">QueinDecim</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">God in his heaven all's right with the world</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensor-%E5%92%8C-Function"><span class="nav-number">1.</span> <span class="nav-text">Tensor 和 Function</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Gradients"><span class="nav-number">2.</span> <span class="nav-text">Gradients</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">3.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Jeff Wong"
      src="/images/spike_smoke.jpg">
  <p class="site-author-name" itemprop="name">Jeff Wong</p>
  <div class="site-description" itemprop="description">本当の声は いつだって 正しい道を照らしてる</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">53</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">74</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/MAGI003769" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;MAGI003769" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/ruihao.wang.777" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;ruihao.wang.777" rel="noopener" target="_blank"><i class="fab fa-facebook fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.instagram.com/jeffwooong/" title="Instagram → https:&#x2F;www.instagram.com&#x2F;jeffwooong&#x2F;" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/p/1005052622574043/home?from=page_100505&mod=TAB#place" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;p&#x2F;1005052622574043&#x2F;home?from&#x3D;page_100505&amp;mod&#x3D;TAB#place" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i></a>
      </span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://magi003769.github.io/post/pytorch_autograd/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/spike_smoke.jpg">
      <meta itemprop="name" content="Jeff Wong">
      <meta itemprop="description" content="本当の声は いつだって 正しい道を照らしてる">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QueinDecim">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PyTorch Note (2) —— Autograd
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2018-06-22 00:00:00" itemprop="dateCreated datePublished" datetime="2018-06-22T00:00:00+08:00">2018-06-22</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-05-11 07:09:36" itemprop="dateModified" datetime="2020-05-11T07:09:36+08:00">2020-05-11</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a>
        </span>
    </span>

  

</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p><code>autograd</code> 包是 pytorch 构建神经网络的核心。他为所有的张量运算提供了自动求导的方法。而这是一个 <strong>define-by-run</strong> 的框架，这意味着反向传播的过程取决于你的代码如何运行。甚至每一次迭代都可以有所不同。</p>
<a id="more"></a>

<h1 id="Tensor-和-Function"><a href="#Tensor-和-Function" class="headerlink" title="Tensor 和 Function"></a>Tensor 和 Function</h1><p><code>torch.tensor</code> 是整个包的核心类。设置它的 attribute <code>.require_grad</code> 为   <code>Ture</code>，这个对象就会开始追踪所有的运算。当计算过程完成后，可以调用 <code>.backward()</code> 来自动计算梯度。一个张量的梯度将会被储存在其 <code>.grad</code> 这一 attribute 中。</p>
<p>如果想要终止对张量的追踪，可以调用 <code>.detech()</code>。这样这两就和运算追踪分离，且将来的运算也不会再追踪。除此之外，还可以用 <code>with torch.no_grad():</code> 来包含一整块代码。<strong>这个方法在评价模型的时候就非常有帮助</strong>，因为模型中包含了许多可训练的参数<code>require_grad=True</code>，但此时我们并不需要这些梯度信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化一个 tensor</span></span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对tensor进行一次运算, y 是一个运算的结果，所以它有 grad_fn</span></span><br><span class="line">y = x + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">print(y.grad_fn) <span class="comment"># 输出一个实例的信息</span></span><br><span class="line">print(x.grad_fn) <span class="comment"># 输出 None</span></span><br></pre></td></tr></table></figure>

<p>对于梯的实现来讲，另一个非常重要的类就是 <code>Funciton</code> 了。<code>Tensor</code> 和 <code>Function</code> 是相互关联的，它们组成了一个 acyclic graph (???) 用来编码和记录完整的运算记录 (history of computation)。每一个变量都有 <code>.grad_fn</code> 这一 attribute 用来索引生成张量的<code>Function</code>。<strong><em>我们可以理解为，整个图是由张量和运算这两个最重要的元素所组成的，<code>Funciton</code> 可以简单地对应到运算上去，通过运算得到的变量就回具有 <code>.grad_fn</code>。</em></strong></p>
<p>当计算倒数时，对一个张量对象调用 <code>.backward()</code>。如果该张量是一个标量，则不需要对 <code>.backward()</code> 指定任何的参数。然而，如果它包含了其他很多元素，那么他就需要指定和张量匹配维度的参数。</p>
<h1 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Simple gradient: output is scalar</span></span><br><span class="line">a1 = torch.tensor([<span class="number">2</span>,<span class="number">3</span>], requires_grad=<span class="literal">True</span>, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">a2 = torch.tensor([<span class="number">2</span>,<span class="number">2</span>], requires_grad=<span class="literal">True</span>, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">b = a1 + <span class="number">3</span></span><br><span class="line">print(b.requires_grad)</span><br><span class="line">c = b * b * <span class="number">3</span> + a2</span><br><span class="line">out = c.mean()</span><br><span class="line">out.backward()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;\n======== Simple gradient =========&quot;</span>)</span><br><span class="line">print(<span class="string">&#x27;\nInput:\n&#x27;</span>, a)</span><br><span class="line">print(<span class="string">&#x27;\nComputation result:\n&#x27;</span>, out)</span><br><span class="line">print(<span class="string">&#x27;\nInput gradient: \n&#x27;</span>, a1.grad)</span><br><span class="line">print(<span class="string">&#x27;\nInput gradient: \n&#x27;</span>, a2.grad)</span><br><span class="line">print(<span class="string">&#x27;\nInput gradient: \n&#x27;</span>, b.grad)</span><br></pre></td></tr></table></figure>

<p>第一个 case 适当最后的张量是一个标量时，可以直接调用 <code>.backward()</code> ，而不需要传参。最终结果的表达式以及偏导数为。于是我最终应该得到的目标是一个 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.977ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3004.2 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">[15, 18]</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-5B" x="0" y="0"></use>
<g transform="translate(278,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-35" x="500" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1279" y="0"></use>
<g transform="translate(1724,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-38" x="500" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-5D" x="2725" y="0"></use>
</g>
</svg> 的向量。</p>
<p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="20.009ex" style="vertical-align: -15.671ex; max-width: 60000px;" viewBox="0 -1867.7 43055.4 8615.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">out = \frac{1}{2}\sum_{i=0}^{1}3\times(x_i + 3)^2  \\
\frac{\partial out}{\partial x_1}|_{x_1=2} = \frac{1}{2}\times6(x_1+3)^2\times1=15 \\
\frac{\partial out}{\partial x_1}|_{x_2=3} = \frac{1}{2}\times6(x_2+3)^2\times1=18</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path>
<path stroke-width="1" id="E1-MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2202" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path>
<path stroke-width="1" id="E1-MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path>
<path stroke-width="1" id="E1-MJMAIN-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(16033,0)">
 <use xlink:href="#E1-MJMATHI-6F" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-75" x="485" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="1058" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1697" y="0"></use>
<g transform="translate(2475,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMAIN-32" x="60" y="-687"></use>
</g>
</g>
<g transform="translate(3780,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-30" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="771" y="1627"></use>
</g>
 <use xlink:href="#E1-MJMAIN-33" x="5391" y="0"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="6114" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="7115" y="0"></use>
<g transform="translate(7504,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="8643" y="0"></use>
 <use xlink:href="#E1-MJMAIN-33" x="9644" y="0"></use>
<g transform="translate(10145,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
</g>
<g transform="translate(13351,-3029)">
<g transform="translate(120,0)">
<rect stroke="none" width="2107" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="567" y="0"></use>
 <use xlink:href="#E1-MJMATHI-75" x="1053" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="1625" y="0"></use>
</g>
<g transform="translate(256,-736)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
<g transform="translate(567,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
</g>
</g>
<g transform="translate(2347,0)">
 <use xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
<g transform="translate(278,-286)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-31" x="705" y="-243"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="1078" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="1857" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="4670" y="0"></use>
<g transform="translate(5449,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMAIN-32" x="60" y="-687"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="6809" y="0"></use>
 <use xlink:href="#E1-MJMAIN-36" x="7810" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="8310" y="0"></use>
<g transform="translate(8700,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="9948" y="0"></use>
 <use xlink:href="#E1-MJMAIN-33" x="10949" y="0"></use>
<g transform="translate(11450,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="12515" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="13516" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="14294" y="0"></use>
<g transform="translate(15351,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-35" x="500" y="0"></use>
</g>
</g>
<g transform="translate(13351,-5738)">
<g transform="translate(120,0)">
<rect stroke="none" width="2107" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="567" y="0"></use>
 <use xlink:href="#E1-MJMATHI-75" x="1053" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="1625" y="0"></use>
</g>
<g transform="translate(256,-736)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
<g transform="translate(567,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
</g>
</g>
<g transform="translate(2347,0)">
 <use xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
<g transform="translate(278,-286)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-32" x="705" y="-243"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="1078" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-33" x="1857" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="4670" y="0"></use>
<g transform="translate(5449,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMAIN-32" x="60" y="-687"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="6809" y="0"></use>
 <use xlink:href="#E1-MJMAIN-36" x="7810" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="8310" y="0"></use>
<g transform="translate(8700,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="9948" y="0"></use>
 <use xlink:href="#E1-MJMAIN-33" x="10949" y="0"></use>
<g transform="translate(11450,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="12515" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="13516" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="14294" y="0"></use>
<g transform="translate(15351,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-38" x="500" y="0"></use>
</g>
</g>
</g>
</svg></p>
<p>在所实验的时候，出现了一些有趣的现象。为了验证链式法则，我尝试着得到中间张量的梯度信息，然而发现并不能够成功。感觉 pytorch 的计算图实现中，类似于这样的树状结构，只能对包含 <code>requires_flag=True</code> 的叶节点的计算图求梯度。<br><img src="http://post-pic.nos-eastchina1.126.net/PyTorch/leaf.PNG" alt="tree_structure"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Complex case: output is NOT scalar</span></span><br><span class="line">m = torch.tensor([<span class="number">2</span>,<span class="number">3</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">n = torch.zeros(<span class="number">2</span>) <span class="comment"># torch.tensor([0,0], requires_grad=True)</span></span><br><span class="line">l = torch.zeros(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n[<span class="number">0</span>] = <span class="number">2</span> * m[<span class="number">0</span>]</span><br><span class="line">n[<span class="number">1</span>] = <span class="number">3</span> * m[<span class="number">1</span>]</span><br><span class="line">l[<span class="number">0</span>] = n[<span class="number">0</span>] ** <span class="number">2</span></span><br><span class="line">l[<span class="number">1</span>] = n[<span class="number">1</span>] ** <span class="number">3</span></span><br><span class="line">l.backward(torch.tensor([<span class="number">1</span>,<span class="number">1</span>])) <span class="comment"># !!!!!</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;\n======== Complex gradient =========&quot;</span>)</span><br><span class="line">print(<span class="string">&#x27;\nInput:\n&#x27;</span>, m)</span><br><span class="line">print(<span class="string">&#x27;\nComputation result:\n&#x27;</span>, l)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;\nInput gradient: \n&#x27;</span>, n.grad)</span><br><span class="line">print(<span class="string">&#x27;\nInput gradient: \n&#x27;</span>, m.grad)</span><br></pre></td></tr></table></figure>

<p>第二个 case 是最终的结果是一个 vector，这时我们就需要给 <code>.backward()</code> 一个参数。<strong>这个参数的大小 (shape) 必须和求导的 vector 一致。这个参数的含义实际上给每个偏导的一个权值。</strong>这里权值都是 1，所以对球到结果并不产生任何影响。</p>
<p>其实，在实验里还有一些问题</p>
<ul>
<li><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.284ex" height="5.843ex" style="vertical-align: -2.338ex;" viewBox="0 -1508.9 1844.3 2515.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\frac{\partial l}{\partial x_i}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-2202" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(120,0)">
<rect stroke="none" width="1604" height="60" x="0" y="220"></rect>
<g transform="translate(369,676)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6C" x="567" y="0"></use>
</g>
<g transform="translate(60,-736)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
<g transform="translate(567,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
</g>
</g>
</g>
</svg> 应该有几个值 4/2？</li>
<li>第二个 case 中，如果张量 <code>n</code> 的生成为注释部分，就会最终只得到 <code>n</code> 的梯度信息，而 <code>m</code> 的就会消失。为什么？明明两个都是 <code>requires_grad=True</code>。</li>
</ul>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/demian/p/8011733.html">CSDN - PyTorch中的backward</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/autograd.html?highlight=grad_fn">Autograd mechanics</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/douhaoexia/article/details/78821428"><strong>Pytorch的backward()相关理解</strong></a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/PyTorch/" rel="tag"><i class="fa fa-tag"></i> PyTorch</a>
              <a href="/tags/Frameworks/" rel="tag"><i class="fa fa-tag"></i> Frameworks</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/PCA/" rel="prev" title="经典的降维方法——PCA">
                  <i class="fa fa-chevron-left"></i> 经典的降维方法——PCA
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B/" rel="next" title="机器学习模型——逻辑斯谛回归">
                  机器学习模型——逻辑斯谛回归 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-bolt"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"><a target="_blank" rel="noopener" href="https://magi003769.github.io/"><b>Jeff Wong</b></a></span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  
















  <script>
    NProgress.configure({
      showSpinner: true
    });
    NProgress.start();
    document.addEventListener('readystatechange', () => {
      if (document.readyState === 'interactive') {
        NProgress.inc(0.8);
      }
      if (document.readyState === 'complete') {
        NProgress.done();
      }
    });
    document.addEventListener('pjax:send', () => {
      NProgress.start();
    });
    document.addEventListener('pjax:success', () => {
      NProgress.done();
    });
  </script>


  








  

  

</body>
</html>
